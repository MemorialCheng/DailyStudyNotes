# 4 CNN卷积神经网络
## 4.1 卷积神经网络基本知识
图像分类常用经典算法：
LeNet  1988年;
AlexNet;
VggNet;
GoogleNet;
ResNet;

目标检测算法：
Faster R-CNN;
SSD;
Yolo v3	2018年;

### 4.1.1一般架构
Convolution 卷积层：进行特征提取，拥有局部感知机制，权值共享；

Pooling 池化层：对特征图进行稀疏处理，减少数据运算；

Full connected 全连接层

### 4.1.2 二维input
__场景1：步长=1__

__假设input为n\*n，pading填充为 p，filter为f\*f，则将output为(n + 2p - f + 1) * (n + 2p - f + 1)__

如果想要input与output相同size,则p=(f-1)/2. It's actually almost always odd.

__场景2：步长stride>1__

公式：__[(n + 2p - f)/s + 1] * [(n + 2p - f)/s +1]__

### 4.1.3 三维input

__存在多个filter__
Nf表示filters个数

公式：__[(n + 2p - f)/s + 1] * [(n + 2p - f)/s +1] * Nf__
## 4.2 经典神经网络
### 4.2.1 LeNet-5
1988年 cov1,avg pool1,cov1,avg pool1,FCFC,softmax


### 4.2.2 AlexNet
首次使用GPU进行网络加速训练；使用了RuLU激活函数，而不是传统的Sigmoid激活函数以及Tanh;使用了LRN局部相应归一化;在全连接层的前两层使用了Dropout随机失活神经元操作，减少过拟合。

<img src="https://github.com/MemorialCheng/EverybodyEveryday/blob/master/DeepLearning/images/AlexNet01.png" width = "800">

<img src="https://github.com/MemorialCheng/EverybodyEveryday/blob/master/DeepLearning/images/AlexNet.png" width = "800">

### 4.2.3 Vgg-16
2014年

<img src="https://github.com/MemorialCheng/EverybodyEveryday/blob/master/DeepLearning/images/Vgg-16.png" width = "800">

<img src="https://github.com/MemorialCheng/EverybodyEveryday/blob/master/DeepLearning/images/vgg_16.png" width="800">

### 4.2.4 GoogleNet
2014年 GoogleNet团队提出。优点：引入了Inception结构（融合不同尺度的特征信息）；使用1x1卷积核进行降维以及映射处理；
添加两个辅助分类器帮助训练；丢去全连接层，使用平均池化层（大大减少模型参数）。

### 4.2.5 残差网络(ResNets)（Residual Networks）
非常非常深的神经网络是很难训练的，因为存在梯度消失和梯度爆炸问题。这节课我们学习跳跃连接（Skip connection），它可以从某一层网络层获取激活，然后迅速反馈给另外一层，甚至是神经网络的更深层。

ResNets是由残差块（Residual block）构建的

> 梯度消失、梯度爆炸 

> 退化问题(degradation problem)

<img src="https://github.com/MemorialCheng/EverybodyEveryday/blob/master/DeepLearning/images/ResNet_1.png" width="800">
<img src="https://github.com/MemorialCheng/EverybodyEveryday/blob/master/DeepLearning/images/ResNet_2.png" width="800">
<img src="https://github.com/MemorialCheng/EverybodyEveryday/blob/master/DeepLearning/images/ResNet_3.png" width="400">

# 5 RNN循环神经网络(Recurrent Neural Networks)
## 5.1 循环神经网络基本知识

激活函数常用Tanh,偶尔也用Relu


## 5.2 GRU
<img src="https://github.com/MemorialCheng/EverybodyEveryday/blob/master/DeepLearning/images/GRU.png" width=500>

## 5.3 LSTM
<img src="https://github.com/MemorialCheng/EverybodyEveryday/blob/master/DeepLearning/images/LSTM_AndrewNg.png" width=500>


## GRU与LSTM对比

<img src="https://github.com/MemorialCheng/EverybodyEveryday/blob/master/DeepLearning/images/GRU_LSTM.png" width=500>

