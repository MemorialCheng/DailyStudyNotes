---
# 总结算法常见面试题，简答
---
# 1 决策树
决策树学习的算法通常是一个递归地选择最优特征，并根据该特征对训练数据进行分割，使得对各个子数据集有一个最好的分类的过程。  
一般而言，决策树的生成包括特征选择、树的构造、树的剪枝三个过程。
## 1.1 特征选择
特征选择的准则是信息增益或信息增益比。
### 1.1.1 信息增益
__熵(entropy)__ H(X)是度量样本集合纯度(不确定性)的一种常用指标。熵越小，纯度越高。  
H(X) = -求和(PilogPi)  
__条件熵__ H(Y|X)表示在已知随机变量X的条件下随机变量Y的不确定性。  
H(Y|X) = 求和PiH(H|X=xi)  
当熵和条件熵中的概率由数据估计（特别是极大似然估计）得到时，所对应的熵和条件熵分布称为经验熵和经验条件熵。  
__信息增益__ 就是经验熵和经验条件熵之差。
<img>(https://github.com/MemorialCheng/EverybodyEveryday/upload/master/leetcode_offer/picture/entropy.jpg size=400)
